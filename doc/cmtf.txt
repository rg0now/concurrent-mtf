#+LaTeX_HEADER:\usepackage[margin=2cm]{geometry}
#+LaTeX_HEADER:\usepackage{enumitem}
#+LaTeX_HEADER:\usepackage{tikz}
#+LaTeX_HEADER:\usepackage{fancyvrb}
#+LATEX:\setitemize{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}
#+LATEX:\fvset{baselinestretch=.5,samepage=true,xleftmargin=1cm,fontsize=\small}
#+OPTIONS: toc:nil author:t
#+OPTIONS: |:nil

#+TITLE: Beating Amdahl's Law with Parallel Self-adjusting Data Structures
#+AUTHOR:

* Abstract
One major obstacle faced by network engineers is how to harness the massive computing power, which
increasingly comes in the form of parallel processing cores, given that Amdahl's law predicts
diminishing returns for massive-scale parallelization.  Using three simple illustrative models, we
show that the combination of /locality-boosting load-balancing/ and /parallel self-adjusting data
structures/ allows to achieve superlinear scaling for some typical massively parallel networking
workloads. We demonstrate quadratic scale-up in certain cases and, strikingly, we show that
parallelization yields linear scaling even if we keep the total available computing power constant.

* Introduction
- simply put, Amdahl's law states that throwing additional processors to a fixed-size parallel
  computation will yield diminishing returns
- Amdahl's law is usually stated in terms of speedup, but it can be interpreted in the usual
  goodput vs. CPU-cores coordinate system as well.

#+begin_src gnuplot :file usl.png :results none
  reset
  set terminal png size 800, 600 font "Helvetica,14"
  set title "Goodput vs. #thread"
  set size 1,1
  set xrange [1:10]
  # set yrange [0:16]
  set xlabel "#thread"
  set ylabel "Goodput [req/sec]"
  f(x) = x
  g(x) = x/(1 +.1*(x-1))
  h(x) = x/(1+.4*(x-1))
  plot f(x) w lines title 'linear scaling', \
       g(x) w lines title 'Amdahls law (serial part: 0,1)', \
       h(x) w lines title 'Amdahls law (serial part: 0,4)'
#+end_src

#+ATTR_LATEX: :width 9cm
[[file:usl.png]]

* Motivation

- the pattern "distribute requests to a set of concurrent worker threads" is fairly familiar in
  networking
  - endhost network stacks: NIC hashes packet headers and RSS distributes packets based on the hash
    across a set of CPUs
  - HTTP load-balancers with "sticky sessions": split requests based on the source IP and allocate
    each to a backend server, same user will always end up at the same backend
  - sharded key-value stores (like REDIS): client splits queries based on the key-hash, each shard
    handles only a subset of the hash-space
  - anything else?
- this pattern has proved remarkably useful: since networking workloads are typically massively
  parallel, with minimal need for synchronization across the threads, we usually get linear
  speed-up
- of course, the load-balancer is still serial so Amdahl's law curtails max performance at the
  load-balancer's throughput
- we argue that there is even more to this model than we would have thought, which may even yield
  superlinear speedup for careful implementations
- this is made possible by the unique combination of two important components, locality boosting
  load-balancing and self-adjusting worker threads, that may further improve efficiency even
  without us being aware

** Locality boosting load-balancing
- the idea in all use-cases above is that requests to the same or "similar" items are processes at
  the same worker: 5-tuple hashes in RSS, per-source-IP load-splitting in HTTP load-balancers,
  key-hashes in sharded key-value stores, they always keep similar jobs at the same worker (TODO:
  make this argument more precise!)
- this improves temporal and/or spatial locality as experienced by the worker threads
- round-robin or random load-balancing promote locality in the input to the workers: not "locality
  boosting"
- hash-based load-balancing or range-based splitting: improves locality (TODO: can we reason about
  this in simple terms?)

** Self-adjusting data structures
- a self-adjusting data structure can rearrange itself as queries are committed to it in order to
  improve efficiency on future requests
- exploit locality of reference in the input
- red-black trees or AVL trees rearrange with respect to the stored data to keep the search tree
  balanced: not self-adjusting

** Idea
- a locality boosting load-balancer splits requests so that worker threads experience improved
  locality of reference
- self-adjusting data structures at the workers exploit the improved locality in the input they
  process
- the more threads the greater the locality in the per-thread request sequences, and the more
  efficient the self-adjustments
- the superlinear scaling thanks to self-adjustments initially outweigh the slowdowns predicted by
  Amdahl's law
- eventually of course Amdahl's law kicks in and performance saturates, but up to that point we
  expect superlinear scaling

* Case Studies

** Model
- a source emits requests (jobs) for $m$ items (we assume a uniform source below)
- a job scheduler (essentially a load-balancer) allocates the requests to workers
- $k$ parallel worker threads running on $n\le k$ CPU cores
- models implemented in Go, evaluated on a 24-core Intel x86 server

:                                        +--------+
:                                 +----->|Thread 1|
:                                 |      +--------+
:                                 |
:                                 |      +--------+
:   +------+    +-------------+   +----->|Thread 2
:   |Source|----|Load-balancer|---+      +--------+
:   +------+    +-------------+   |          .
:                                 |          .
:                                 |          .
:                                 |      +--------+
:                                 +----->|Thread k|
:                                        +--------+

** Caching
- simplest self-adjusting data-structure: LRU cache
- we get caches by default in all current CPUs, but many networking applications explicitly contain
  a fast-path/cache component: key-value stores [ebpf/NSDI], FIB caching [linux], flow-caches as a
  fast-path in OvS, etc.
- strikingly, caches alone, paired with a locality boosting load-balancer (like RSS), can already
  provide superlinear scaling as we show below
*** Analysis
- lookup time: $l = \delta + (1-\delta)\rho$, where $\delta$ is the cache hit rate and $\rho$ is
  the cost of a cache miss; we assume $\delta=.025$ and $\rho=100$
- if all requests are processed on a single thread, that thread will experience a cache hit rate of
  $\delta$ on $m$ items
- if the request set is randomly split into $k$ partitions, then the working set at each thread
  reduces to $\frac{m}{k}$ and so we expect the cache hit rate to increase to $k\delta$ at each of
  the threads
- lookup time on $k$ threads: $l_k = k\delta + (1-k\delta)\rho = \rho - k\delta(\rho-1)$
- throughput on $k$ threads: $t_k = \frac1{l_k} = \frac1{\rho - k\delta(\rho-1)}$
- throughput on $n$ cores with $k\ge n$ threads: $t_k(n) = \frac{n}{\rho - k\delta(\rho-1)}$
- for $n=k$ this yields superlinear $O(\frac{k}{b - k})$ scaling
    
*** Multicore scaling
- $n=k$: superlinear scaling confirmed

#+TBLNAME:tab-cache-no-cpu-bound
|  c |     m |       n | t             |              q |
|----+-------+---------+---------------+----------------|
|  1 | 10000 | 5000000 | 57.812176314s |   86486.970718 |
|  2 | 10000 | 5000000 | 33.798581782s |  147935.201313 |
|  3 | 10000 | 5000000 | 21.705486973s |  230356.499544 |
|  4 | 10000 | 5000000 | 16.841774165s |  296880.836366 |
|  5 | 10000 | 5000000 | 13.688139998s |  365279.723960 |
|  6 | 10000 | 5000000 | 11.462462108s |  436206.458341 |
|  7 | 10000 | 5000000 | 9.779497932s  |  511273.690609 |
|  8 | 10000 | 5000000 | 8.673478947s  |  576469.952894 |
|  9 | 10000 | 5000000 | 7.598323029s  |  658039.936038 |
| 10 | 10000 | 5000000 | 6.767909711s  |  738780.541335 |
| 11 | 10000 | 5000000 | 6.15325886s   |  812577.548541 |
| 12 | 10000 | 5000000 | 5.453913177s  |  916772.936739 |
| 13 | 10000 | 5000000 | 4.94787892s   | 1010534.024951 |
| 14 | 10000 | 5000000 | 4.475749662s  | 1117131.291424 |
| 15 | 10000 | 5000000 | 4.044105161s  | 1236367.453601 |
| 16 | 10000 | 5000000 | 3.671876681s  | 1361701.504267 |
| 17 | 10000 | 5000000 | 3.350823132s  | 1492170.670618 |
| 18 | 10000 | 5000000 | 3.032115641s  | 1649013.623488 |
| 19 | 10000 | 5000000 | 2.78509161s   | 1795273.082597 |
| 20 | 10000 | 5000000 | 2.449524476s  | 2041212.508382 |
| 21 | 10000 | 5000000 | 2.183347675s  | 2290061.293147 |
| 22 | 10000 | 5000000 | 2.0630233s    | 2423627.498536 |
| 23 | 10000 | 5000000 | 2.053604399s  | 2434743.518486 |
| 24 | 10000 | 5000000 | 1.98803672s   | 2515044.088320 |
| 25 | 10000 | 5000000 | 1.983191713s  | 2521188.429351 |
| 26 | 10000 | 5000000 | 2.020367983s  | 2474796.691529 |
| 27 | 10000 | 5000000 | 2.184296411s  | 2289066.618807 |
| 28 | 10000 | 5000000 | 2.234938237s  | 2237198.289073 |
| 29 | 10000 | 5000000 | 2.187192702s  | 2286035.425881 |
| 30 | 10000 | 5000000 | 2.230632224s  | 2241516.977207 |
| 31 | 10000 | 5000000 | 2.266547692s  | 2205998.143188 |
| 32 | 10000 | 5000000 | 2.303967322s  | 2170169.668752 |
| 33 | 10000 | 5000000 | 2.269787558s  | 2202849.329391 |
| 34 | 10000 | 5000000 | 2.241996094s  | 2230155.535677 |
| 35 | 10000 | 5000000 | 2.255358875s  | 2216942.082000 |
| 36 | 10000 | 5000000 | 2.252480172s  | 2219775.366795 |
| 37 | 10000 | 5000000 | 2.236739797s  | 2235396.359785 |
| 38 | 10000 | 5000000 | 2.292851649s  | 2180690.583353 |
| 39 | 10000 | 5000000 | 2.446468182s  | 2043762.529506 |
| 40 | 10000 | 5000000 | 3.117085443s  | 1604062.542215 |
| 41 | 10000 | 5000000 | 3.126849914s  | 1599053.404391 |
| 42 | 10000 | 5000000 | 3.208609706s  | 1558307.322530 |
| 43 | 10000 | 5000000 | 3.367728259s  | 1484680.358826 |
| 44 | 10000 | 5000000 | 3.180454236s  | 1572102.482534 |
| 45 | 10000 | 5000000 | 3.314044311s  | 1508730.581364 |
| 46 | 10000 | 5000000 | 3.368794286s  | 1484210.544045 |
| 47 | 10000 | 5000000 | 3.377814623s  | 1480247.011175 |
| 48 | 10000 | 5000000 | 3.355707366s  | 1489998.815350 |

#+begin_src gnuplot :var data=tab-cache-no-cpu-bound :file cache-no-cpu-bound.png :results none
  reset
  set terminal png size 800, 600 font "Helvetica,14"
  set title "Throughput vs. # thread (#req/sec)"
  set size 1,1
  #set xrange [1:48]
  set xrange [1:30]
  # set yrange [0:16]
  set xlabel "#thread"
  set ylabel "Req/sec"
  f(x) = 70000*x
  plot f(x) w lines title 'linear scaling', \
       data u 1:5 w lp lw 2 title 'cache'
#+end_src

#+ATTR_LATEX: :width 9cm
[[file:cache-no-cpu-bound.png]]
  
*** Scaling on a single core
- $n=1$: we see a linear yield for running $k$ parallel threads even if we restrict the system to a
  single CPU core
  
#+TBLNAME:tab-cache-cpu-bound-150
|  c |     m |       n | t               |             q |
|----+-------+---------+-----------------+---------------|
|  1 | 10000 | 5000000 | 1m17.941905226s |  64150.343586 |
|  2 | 10000 | 5000000 | 1m8.59337082s   |  72893.341444 |
|  3 | 10000 | 5000000 | 58.594014373s   |  85332.948314 |
|  4 | 10000 | 5000000 | 51.976671091s   |  96197.003291 |
|  5 | 10000 | 5000000 | 54.323366752s   |  92041.423405 |
|  6 | 10000 | 5000000 | 51.127375823s   |  97794.966386 |
|  7 | 10000 | 5000000 | 47.579880541s   | 105086.434500 |
|  8 | 10000 | 5000000 | 47.560267705s   | 105129.769896 |
|  9 | 10000 | 5000000 | 43.226802623s   | 115668.976112 |
| 10 | 10000 | 5000000 | 41.764762679s   | 119718.147052 |
| 11 | 10000 | 5000000 | 45.806748585s   | 109154.221910 |
| 12 | 10000 | 5000000 | 41.556985783s   | 120316.714646 |
| 13 | 10000 | 5000000 | 39.562768404s   | 126381.449067 |
| 14 | 10000 | 5000000 | 36.71956317s    | 136167.197220 |
| 15 | 10000 | 5000000 | 34.058541245s   | 146806.052674 |
| 16 | 10000 | 5000000 | 32.447085726s   | 154097.044099 |
| 17 | 10000 | 5000000 | 31.758081331s   | 157440.241679 |
| 18 | 10000 | 5000000 | 26.552626165s   | 188305.291120 |
| 19 | 10000 | 5000000 | 25.610677397s   | 195231.071888 |
| 20 | 10000 | 5000000 | 22.875808506s   | 218571.509667 |
| 21 | 10000 | 5000000 | 21.107327075s   | 236884.565357 |
| 22 | 10000 | 5000000 | 21.056311107s   | 237458.497578 |
| 23 | 10000 | 5000000 | 20.216434845s   | 247323.528522 |
| 24 | 10000 | 5000000 | 20.255166763s   | 246850.596616 |
| 25 | 10000 | 5000000 | 19.352665351s   | 258362.344892 |
| 26 | 10000 | 5000000 | 19.248412552s   | 259761.680943 |
| 27 | 10000 | 5000000 | 19.312998045s   | 258892.999852 |
| 28 | 10000 | 5000000 | 18.495803664s   | 270331.589307 |
| 29 | 10000 | 5000000 | 18.526468377s   | 269884.140801 |
| 30 | 10000 | 5000000 | 18.473401868s   | 270659.407278 |
| 31 | 10000 | 5000000 | 18.573049088s   | 269207.278585 |
| 32 | 10000 | 5000000 | 16.111182669s   | 310343.449188 |
| 33 | 10000 | 5000000 | 16.793649125s   | 297731.598581 |
| 34 | 10000 | 5000000 | 14.852431069s   | 336645.225066 |
| 35 | 10000 | 5000000 | 12.94253624s    | 386323.044207 |
| 36 | 10000 | 5000000 | 12.121023138s   | 412506.431435 |
| 37 | 10000 | 5000000 | 11.403210282s   | 438473.015611 |
| 38 | 10000 | 5000000 | 10.834067656s   | 461507.178906 |
| 39 | 10000 | 5000000 | 9.795984621s    | 510413.214541 |
| 40 | 10000 | 5000000 | 9.822993758s    | 509009.791025 |
| 41 | 10000 | 5000000 | 10.27370293s    | 486679.441100 |
| 42 | 10000 | 5000000 | 10.241200638s   | 488224.005831 |
| 43 | 10000 | 5000000 | 10.677557104s   | 468271.904453 |
| 44 | 10000 | 5000000 | 10.361413861s   | 482559.626232 |
| 45 | 10000 | 5000000 | 10.419632034s   | 479863.394761 |
| 46 | 10000 | 5000000 | 10.472656611s   | 477433.776903 |
| 47 | 10000 | 5000000 | 10.876722613s   | 459697.298341 |
| 48 | 10000 | 5000000 | 11.02820276s    | 453383.031561 |

#+begin_src gnuplot :var data=tab-cache-cpu-bound-150 :file cache-cpu-bound-150.png :results none
  reset
  set terminal png size 800, 600 font "Helvetica,14"
  set title "Throughput vs. # thread (#req/sec)"
  set size 1,1
  #set xrange [1:48]
  set xrange [1:30]
  # set yrange [0:16]
  set xlabel "#thread"
  set ylabel "Req/sec"
  f(x) = 7000*x+60000
  plot f(x) w lines title 'linear scaling', \
       data u 1:5 w lp lw 2 title 'cache'
#+end_src

#+ATTR_LATEX: :width 9cm
[[file:cache-cpu-bound-150.png]]

** Move-to-front lists
- classical applications: information retrieval
- networking: packet classification, ternary flow tables, intrusion detection

*** Analysis
- average lookup time on one thread is $\frac1{2}m$, where the working-set size equals $m$
- randomly splitting items to $k$ partitions also partition the working sets, yielding $l_k =
  \frac{m}{2k}$ lookup time
- throughput on $k$ threads: $t_k = \frac1{l_k} = \frac{2 k}{m}$
- throughput on $n$ cores with $k\ge n$ threads: $t_k(n) = \frac{2k n}{m}$
- for $n=k$ this yields $O(k^2)$ scaling
  
*** Multicore scaling
- $n=k$
#+TBLNAME:tab-cmtf-no-cpu-bound
|  c |     m |       n | t               |              q |
|----+-------+---------+-----------------+----------------|
|  1 | 10000 | 5000000 | 4m55.172740092s |   16939.233611 |
|  2 | 10000 | 5000000 | 1m58.847537244s |   42070.707698 |
|  3 | 10000 | 5000000 | 55.547035097s   |   90013.805260 |
|  4 | 10000 | 5000000 | 32.310185306s   |  154749.963600 |
|  5 | 10000 | 5000000 | 20.231613391s   |  247137.976758 |
|  6 | 10000 | 5000000 | 14.86122498s    |  336446.020212 |
|  7 | 10000 | 5000000 | 12.400916766s   |  403195.997066 |
|  8 | 10000 | 5000000 | 10.272098178s   |  486755.472286 |
|  9 | 10000 | 5000000 | 7.874612789s    |  634951.855282 |
| 10 | 10000 | 5000000 | 6.26937453s     |  797527.724030 |
| 11 | 10000 | 5000000 | 5.136083422s    |  973504.436977 |
| 12 | 10000 | 5000000 | 4.35448288s     | 1148241.969894 |
| 13 | 10000 | 5000000 | 3.560504818s    | 1404295.249012 |
| 14 | 10000 | 5000000 | 3.014117852s    | 1658860.152626 |
| 15 | 10000 | 5000000 | 2.672688741s    | 1870775.269600 |
| 16 | 10000 | 5000000 | 2.492185233s    | 2006271.417467 |
| 17 | 10000 | 5000000 | 2.078990144s    | 2405013.806549 |
| 18 | 10000 | 5000000 | 1.959452639s    | 2551733.019968 |
| 19 | 10000 | 5000000 | 1.894689521s    | 2638954.796858 |
| 20 | 10000 | 5000000 | 1.913246516s    | 2613358.999055 |
| 21 | 10000 | 5000000 | 1.913494907s    | 2613019.758615 |
| 22 | 10000 | 5000000 | 1.964156729s    | 2545621.704305 |
| 23 | 10000 | 5000000 | 2.003312221s    | 2495866.569168 |
| 24 | 10000 | 5000000 | 2.02080565s     | 2474260.698945 |
| 25 | 10000 | 5000000 | 2.056737787s    | 2431034.248315 |
| 26 | 10000 | 5000000 | 2.04687456s     | 2442748.616701 |
| 27 | 10000 | 5000000 | 2.020872799s    | 2474178.484897 |
| 28 | 10000 | 5000000 | 2.038282366s    | 2453045.801408 |
| 29 | 10000 | 5000000 | 2.043962721s    | 2446228.567982 |
| 30 | 10000 | 5000000 | 2.019606922s    | 2475729.284513 |
| 31 | 10000 | 5000000 | 2.041222597s    | 2449512.369375 |
| 32 | 10000 | 5000000 | 2.046867465s    | 2442757.083933 |
| 33 | 10000 | 5000000 | 1.981040313s    | 2523926.427539 |
| 34 | 10000 | 5000000 | 2.006051497s    | 2492458.447591 |
| 35 | 10000 | 5000000 | 1.968323629s    | 2540232.676341 |
| 36 | 10000 | 5000000 | 1.969529746s    | 2538677.067536 |
| 37 | 10000 | 5000000 | 1.954204425s    | 2558585.957557 |
| 38 | 10000 | 5000000 | 1.962992192s    | 2547131.883854 |
| 39 | 10000 | 5000000 | 1.971445831s    | 2536209.679910 |
| 40 | 10000 | 5000000 | 1.973333251s    | 2533783.889501 |
| 41 | 10000 | 5000000 | 1.978514538s    | 2527148.476278 |
| 42 | 10000 | 5000000 | 1.942458223s    | 2574057.933806 |
| 43 | 10000 | 5000000 | 1.969548662s    | 2538652.685495 |
| 44 | 10000 | 5000000 | 1.995510079s    | 2505625.029218 |
| 45 | 10000 | 5000000 | 1.984097264s    | 2520037.747504 |
| 46 | 10000 | 5000000 | 1.998972482s    | 2501285.057710 |
| 47 | 10000 | 5000000 | 1.998082129s    | 2502399.639850 |
| 48 | 10000 | 5000000 | 1.956776021s    | 2555223.462645 |

#+begin_src gnuplot :var data=tab-cmtf-no-cpu-bound :file cmtf-no-cpu-bound.png :results none
  reset
  set terminal png size 800, 600 font "Helvetica,14"
  set title "Throughput vs. # thread (#req/sec)"
  set size 1,1
  # set xrange [1:48]
  set xrange [1:20]
  # set yrange [0:16]
  set xlabel "#thread"
  set ylabel "Req/sec"
  f(x) = 16939.23*x
  plot f(x) w lines title 'linear scaling', \
       data u 1:5 w lp lw 2 title 'cmtf'
#+end_src

#+ATTR_LATEX: :width 9cm
[[file:cmtf-no-cpu-bound.png]]

*** Scaling on a single core
- $n=1$
#+TBLNAME:tab-cmtf-cpu-bound-150
|  c |     m |       n | t               |             q |
|----+-------+---------+-----------------+---------------|
|  1 | 10000 | 5000000 | 5m5.864978337s  |  16347.082386 |
|  2 | 10000 | 5000000 | 3m11.158206826s |  26156.344962 |
|  3 | 10000 | 5000000 | 1m53.849376188s |  43917.675857 |
|  4 | 10000 | 5000000 | 1m30.712011306s |  55119.492204 |
|  5 | 10000 | 5000000 | 1m7.481518137s  |  74094.361509 |
|  6 | 10000 | 5000000 | 51.83585907s    |  96458.322283 |
|  7 | 10000 | 5000000 | 49.825555007s   | 100350.111490 |
|  8 | 10000 | 5000000 | 43.463246621s   | 115039.726406 |
|  9 | 10000 | 5000000 | 37.54606558s    | 133169.745558 |
| 10 | 10000 | 5000000 | 32.413415289s   | 154257.117166 |
| 11 | 10000 | 5000000 | 27.59584898s    | 181186.670634 |
| 12 | 10000 | 5000000 | 24.544405055s   | 203712.413839 |
| 13 | 10000 | 5000000 | 22.413730389s   | 223077.547254 |
| 14 | 10000 | 5000000 | 19.73445573s    | 253363.967490 |
| 15 | 10000 | 5000000 | 20.670146842s   | 241894.749864 |
| 16 | 10000 | 5000000 | 21.514589312s   | 232400.438953 |
| 17 | 10000 | 5000000 | 17.657729208s   | 283162.117909 |
| 18 | 10000 | 5000000 | 16.757759719s   | 298369.238123 |
| 19 | 10000 | 5000000 | 16.73655082s    | 298747.337715 |
| 20 | 10000 | 5000000 | 15.923440039s   | 314002.501203 |
| 21 | 10000 | 5000000 | 15.553570558s   | 321469.593194 |
| 22 | 10000 | 5000000 | 15.894692886s   | 314570.406353 |
| 23 | 10000 | 5000000 | 15.913981691s   | 314189.126083 |
| 24 | 10000 | 5000000 | 15.928876565s   | 313895.332141 |
| 25 | 10000 | 5000000 | 15.128961574s   | 330491.949202 |
| 26 | 10000 | 5000000 | 15.092440337s   | 331291.685662 |
| 27 | 10000 | 5000000 | 13.170969048s   | 379622.788709 |
| 28 | 10000 | 5000000 | 14.782389804s   | 338240.302569 |
| 29 | 10000 | 5000000 | 12.848820017s   | 389140.792180 |
| 30 | 10000 | 5000000 | 12.979019098s   | 385237.124797 |
| 31 | 10000 | 5000000 | 12.126760449s   | 412311.269859 |
| 32 | 10000 | 5000000 | 14.676749986s   | 340674.877256 |
| 33 | 10000 | 5000000 | 12.201272085s   | 409793.336725 |
| 34 | 10000 | 5000000 | 12.098187918s   | 413285.033584 |
| 35 | 10000 | 5000000 | 11.481685491s   | 435476.133179 |
| 36 | 10000 | 5000000 | 11.386720631s   | 439107.989212 |
| 37 | 10000 | 5000000 | 11.369277025s   | 439781.701950 |
| 38 | 10000 | 5000000 | 11.368810729s   | 439799.739760 |
| 39 | 10000 | 5000000 | 11.388049972s   | 439056.731600 |
| 40 | 10000 | 5000000 | 11.390339331s   | 438968.485021 |
| 41 | 10000 | 5000000 | 11.378155092s   | 439438.552171 |
| 42 | 10000 | 5000000 | 11.364680442s   | 439959.577000 |
| 43 | 10000 | 5000000 | 11.382835592s   | 439257.859748 |
| 44 | 10000 | 5000000 | 11.487508211s   | 435255.401621 |
| 45 | 10000 | 5000000 | 10.678375777s   | 468236.003716 |
| 46 | 10000 | 5000000 | 11.415822335s   | 437988.596290 |
| 47 | 10000 | 5000000 | 11.431207039s   | 437399.128801 |
| 48 | 10000 | 5000000 | 11.45947038s    | 436320.338916 |

#+begin_src gnuplot :var data=tab-cmtf-cpu-bound-150 :file cmtf-cpu-bound-150.png :results none
  reset
  set terminal png size 800, 600 font "Helvetica,14"
  set title "Throughput vs. # thread (#req/sec)"
  set size 1,1
  set xrange [1:48]
  #set xrange [1:20]
  # set yrange [0:16]
  set xlabel "#thread"
  set ylabel "Req/sec"
  f(x) = 16347*x
  plot f(x) w lines title 'linear scaling', \
       data u 1:5 w lp lw 2 title 'cmtf'
#+end_src

#+ATTR_LATEX: :width 9cm
[[file:cmtf-cpu-bound-150.png]]

** Splay tree
- networking applications: maybe FIB lookups?
  
*** Multicore scaling
- $n=k$

#+TBLNAME:tab-splay-no-cpu-bound
|  c |     m |       n | t            |              q |
|----+-------+---------+--------------+----------------|
|  1 | 10000 | 5000000 | 5.777706951s |  865395.223815 |
|  2 | 10000 | 5000000 | 5.403327404s |  925355.734746 |
|  3 | 10000 | 5000000 | 4.637632357s | 1078136.345252 |
|  4 | 10000 | 5000000 | 3.972044981s | 1258797.426494 |
|  5 | 10000 | 5000000 | 3.165669821s | 1579444.567097 |
|  6 | 10000 | 5000000 | 2.532594705s | 1974259.833257 |
|  7 | 10000 | 5000000 | 2.320253955s | 2154936.527196 |
|  8 | 10000 | 5000000 | 2.326130831s | 2149492.166720 |
|  9 | 10000 | 5000000 | 2.275251076s | 2197559.668355 |
| 10 | 10000 | 5000000 | 2.284595343s | 2188571.387629 |
| 11 | 10000 | 5000000 | 2.303812717s | 2170315.305192 |
| 12 | 10000 | 5000000 | 2.235104921s | 2237031.448959 |
| 13 | 10000 | 5000000 | 2.178286348s | 2295382.333269 |
| 14 | 10000 | 5000000 | 2.144573727s | 2331465.660075 |
| 15 | 10000 | 5000000 | 2.125055334s | 2352879.908585 |
| 16 | 10000 | 5000000 | 2.101994989s | 2378692.635409 |
| 17 | 10000 | 5000000 | 2.012702352s | 2484222.267158 |
| 18 | 10000 | 5000000 | 1.962982706s | 2547144.192721 |
| 19 | 10000 | 5000000 | 1.965667066s | 2543665.754229 |
| 20 | 10000 | 5000000 | 1.970364036s | 2537602.142876 |
| 21 | 10000 | 5000000 | 1.982064591s | 2522622.129825 |
| 22 | 10000 | 5000000 | 1.970192065s | 2537823.641067 |
| 23 | 10000 | 5000000 | 1.903404832s | 2626871.549310 |
| 24 | 10000 | 5000000 | 1.926584539s | 2595266.337285 |
| 25 | 10000 | 5000000 | 1.905543951s | 2623922.684846 |
| 26 | 10000 | 5000000 | 1.93432362s  | 2584882.874976 |
| 27 | 10000 | 5000000 | 1.897444377s | 2635123.358876 |
| 28 | 10000 | 5000000 | 1.882696764s | 2655764.908937 |
| 29 | 10000 | 5000000 | 1.86311574s  | 2683676.538528 |
| 30 | 10000 | 5000000 | 1.86157118s  | 2685903.205700 |
| 31 | 10000 | 5000000 | 1.835044723s | 2724729.232662 |
| 32 | 10000 | 5000000 | 1.843302576s | 2712522.656400 |
| 33 | 10000 | 5000000 | 1.813595311s | 2756954.635730 |
| 34 | 10000 | 5000000 | 1.820459057s | 2746559.984842 |
| 35 | 10000 | 5000000 | 1.879735317s | 2659948.959186 |
| 36 | 10000 | 5000000 | 1.85482821s  | 2695667.433266 |
| 37 | 10000 | 5000000 | 1.890090412s | 2645376.098548 |
| 38 | 10000 | 5000000 | 1.879858763s | 2659774.286458 |
| 39 | 10000 | 5000000 | 1.896984561s | 2635762.094639 |
| 40 | 10000 | 5000000 | 1.945624544s | 2569868.896555 |
| 41 | 10000 | 5000000 | 1.970511412s | 2537412.353743 |
| 42 | 10000 | 5000000 | 1.965947522s | 2543302.882731 |
| 43 | 10000 | 5000000 | 2.007871367s | 2490199.363454 |
| 44 | 10000 | 5000000 | 2.096959169s | 2384405.034641 |
| 45 | 10000 | 5000000 | 2.052111241s | 2436515.087537 |
| 46 | 10000 | 5000000 | 2.114964096s | 2364106.326654 |
| 47 | 10000 | 5000000 | 2.060324077s | 2426802.684013 |
| 48 | 10000 | 5000000 | 2.070375206s | 2415021.193023 |

#+begin_src gnuplot :var data=tab-splay-no-cpu-bound :file splay-no-cpu-bound.png :results none
  reset
  set terminal png size 800, 600 font "Helvetica,14"
  set title "Throughput vs. # thread (#req/sec)"
  set size 1,1
  #set xrange [1:48]
  set xrange [1:20]
  # set yrange [0:16]
  set xlabel "#thread"
  set ylabel "Req/sec"
  f(x) = 865395 + 20000*x
  plot f(x) w lines title 'linear scaling', \
       data u 1:5 w lp lw 2 title 'splaytree'
#+end_src

#+ATTR_LATEX: :width 9cm
[[file:splay-no-cpu-bound.png]]
 
*** Scaling on a single core
- $n=1$

#+TBLNAME:tab-splay-cpu-bound-150
|  c |     m |       n | t             |             q |
|----+-------+---------+---------------+---------------|
|  1 | 10000 | 5000000 | 7.733058441s  | 646574.707556 |
|  2 | 10000 | 5000000 | 10.208535827s | 489786.202912 |
|  3 | 10000 | 5000000 | 10.013682984s | 499316.785641 |
|  4 | 10000 | 5000000 | 10.021437867s | 498930.399645 |
|  5 | 10000 | 5000000 | 9.193758478s  | 543847.221130 |
|  6 | 10000 | 5000000 | 9.064146411s  | 551623.922792 |
|  7 | 10000 | 5000000 | 9.476901332s  | 527598.613179 |
|  8 | 10000 | 5000000 | 9.584533949s  | 521673.774292 |
|  9 | 10000 | 5000000 | 9.637926585s  | 518783.781543 |
| 10 | 10000 | 5000000 | 9.507658848s  | 525891.818368 |
| 11 | 10000 | 5000000 | 9.60091714s   | 520783.580057 |
| 12 | 10000 | 5000000 | 9.525043392s  | 524931.991827 |
| 13 | 10000 | 5000000 | 10.01734129s  | 499134.436499 |
| 14 | 10000 | 5000000 | 9.985845341s  | 500708.736142 |
| 15 | 10000 | 5000000 | 9.8997203s    | 505064.774406 |
| 16 | 10000 | 5000000 | 9.915935269s  | 504238.870501 |
| 17 | 10000 | 5000000 | 9.879100877s  | 506118.933520 |
| 18 | 10000 | 5000000 | 9.971106614s  | 501448.855534 |
| 19 | 10000 | 5000000 | 9.952180537s  | 502402.461592 |
| 20 | 10000 | 5000000 | 9.94428881s   | 502801.165124 |
| 21 | 10000 | 5000000 | 9.5544762s    | 523314.925417 |
| 22 | 10000 | 5000000 | 10.05320523s  | 497353.817574 |
| 23 | 10000 | 5000000 | 9.910670525s  | 504506.732152 |
| 24 | 10000 | 5000000 | 9.916528663s  | 504208.697410 |
| 25 | 10000 | 5000000 | 9.896041031s  | 505252.553454 |
| 26 | 10000 | 5000000 | 9.759239628s  | 512334.996433 |
| 27 | 10000 | 5000000 | 9.540359065s  | 524089.289086 |
| 28 | 10000 | 5000000 | 9.519280959s  | 525249.755894 |
| 29 | 10000 | 5000000 | 9.281059293s  | 538731.608338 |
| 30 | 10000 | 5000000 | 9.824159914s  | 508949.370101 |
| 31 | 10000 | 5000000 | 9.467048106s  | 528147.733487 |
| 32 | 10000 | 5000000 | 9.691743287s  | 515903.058091 |
| 33 | 10000 | 5000000 | 10.001575253s | 499921.249755 |
| 34 | 10000 | 5000000 | 10.083374298s | 495865.754085 |
| 35 | 10000 | 5000000 | 10.322109629s | 484397.102890 |
| 36 | 10000 | 5000000 | 10.09904704s  | 495096.218504 |
| 37 | 10000 | 5000000 | 10.098671526s | 495114.628407 |
| 38 | 10000 | 5000000 | 10.091195001s | 495481.456805 |
| 39 | 10000 | 5000000 | 10.062144319s | 496911.974375 |
| 40 | 10000 | 5000000 | 10.738044995s | 465634.107729 |
| 41 | 10000 | 5000000 | 10.512465302s | 475625.826708 |
| 42 | 10000 | 5000000 | 10.237212156s | 488414.220962 |
| 43 | 10000 | 5000000 | 10.110060422s | 494556.886042 |
| 44 | 10000 | 5000000 | 10.668602847s | 468664.929392 |
| 45 | 10000 | 5000000 | 10.324414174s | 484288.979087 |
| 46 | 10000 | 5000000 | 10.976552292s | 455516.437857 |
| 47 | 10000 | 5000000 | 11.082121874s | 451177.135286 |
| 48 | 10000 | 5000000 | 11.085193986s | 451052.097628 |

#+begin_src gnuplot :var data=tab-splay-cpu-bound-150 :file splay-cpu-bound-150.png :results none
  reset
  set terminal png size 800, 600 font "Helvetica,14"
  set title "Throughput vs. # thread (#req/sec)"
  set size 1,1
  set xrange [1:48]
  #set xrange [1:20]
  # set yrange [0:16]
  set xlabel "#thread"
  set ylabel "Req/sec"
  plot data u 1:5 w lp lw 2 title 'splay'
#+end_src

#+ATTR_LATEX: :width 9cm
[[file:splay-cpu-bound-150.png]]

